{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRRbR7W5i7q4gBG57ssOSy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anonymous143w/DS/blob/main/DS7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "6vGtTclnbzmD"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        " text = text.lower()\n",
        " text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        " return text"
      ],
      "metadata": {
        "id": "o_icLwP7cOhG"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"i am a student.hello!! there is a session going onn.\""
      ],
      "metadata": {
        "id": "LynVngjZieb0"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_document = preprocess_text(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "w1EMvX-gqgs5",
        "outputId": "acb6f4c0-186c-4512-9023-76c1ea80be39"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am a student.hello!! there is a session going onn.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "def tokenize_text(text):\n",
        " tokens = word_tokenize(text)\n",
        " return tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o97LnuJPinSG",
        "outputId": "8df65ea8-dff1-4737-f61b-ed8e168b8d66"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenize_text(preprocessed_document)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rycfcVUpA1oC",
        "outputId": "936f7238-dc39-43eb-88bf-12e05d9ce423"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'student',\n",
              " 'hello',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'session',\n",
              " 'going',\n",
              " 'onn']"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tag_tokens(tokens):\n",
        " pos_tags = pos_tag(tokens)\n",
        " return pos_tags"
      ],
      "metadata": {
        "id": "cX3zUSJjqpCr"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos_tags = pos_tag_tokens(tokens)\n",
        "pos_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Zput-IH8o6",
        "outputId": "2afdd228-0222-4eef-b82d-e012b83fa7ca"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 'NN'),\n",
              " ('am', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('student', 'NN'),\n",
              " ('hello', 'NN'),\n",
              " ('there', 'EX'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('session', 'NN'),\n",
              " ('going', 'VBG'),\n",
              " ('onn', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(tokens):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "  return filtered_tokens"
      ],
      "metadata": {
        "id": "jfAmD2rk0not"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "filtered_tokens = remove_stop_words(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "033YJp9vq5eo",
        "outputId": "c76966c8-eccf-4337-e5b2-51e5e777b1f0"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwsfWnuiCAc0",
        "outputId": "93180b3d-a12b-4e3e-de53-93380decdb8d"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11,  0,  0],\n",
              "       [ 0, 13,  0],\n",
              "       [ 0,  1,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_tokens(tokens):\n",
        " stemmer = PorterStemmer()\n",
        " stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        " return stemmed_tokens"
      ],
      "metadata": {
        "id": "zSWtfarGCAWw"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_tokens = stem_tokens(filtered_tokens)\n",
        "stemmed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxULEfzsCHsc",
        "outputId": "7dee8718-c9ec-433e-fa31-b79cc3f8eb9e"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['student', 'hello', 'session', 'go', 'onn']"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oPNRxyeCQuR",
        "outputId": "ceaa3922-c78e-4d4e-9c25-78f033927894"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_tokens(tokens):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "      return wn.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "      return wn.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "      return wn.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "      return wn.ADV\n",
        "    else:\n",
        "      return None\n",
        "  pos_tags = pos_tag(tokens)\n",
        "  lemmatized_tokens = []\n",
        "  for word, pos in pos_tags:\n",
        "    wordnet_pos = get_wordnet_pos(pos) or wn.NOUN\n",
        "    lemmatized_tokens.append(lemmatizer.lemmatize(word, pos=wordnet_pos))\n",
        "  return lemmatized_tokens"
      ],
      "metadata": {
        "id": "2ZQ09kJzJFFW"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_tokens = lemmatize_tokens(tokens)\n",
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj6A60ZbJkwP",
        "outputId": "ea648dbf-516b-4dc2-9e71-32e425b19ac9"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'be',\n",
              " 'a',\n",
              " 'student',\n",
              " 'hello',\n",
              " 'there',\n",
              " 'be',\n",
              " 'a',\n",
              " 'session',\n",
              " 'go',\n",
              " 'onn']"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tfidf_representation(documents):\n",
        " tfidf_vectorizer = TfidfVectorizer()\n",
        " tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        " return tfidf_matrix"
      ],
      "metadata": {
        "id": "FMXjvoFzJtkv"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = get_tfidf_representation([text])\n",
        "tfidf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RF44C1pJtAV",
        "outputId": "8cf24929-6f5c-4225-e230-9ff5a88fda13"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x8 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Tokens:\")\n",
        "print(tokens)\n",
        "print(\"\\nPOS Tagging:\")\n",
        "print(pos_tags)\n",
        "print(\"\\nFiltered Tokens after Stop Words Removal:\")\n",
        "print(filtered_tokens)\n",
        "print(\"\\nStemmed Tokens:\")\n",
        "print(stemmed_tokens)\n",
        "print(\"\\nLemmatized Tokens:\")\n",
        "print(lemmatized_tokens)\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(tfidf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krRjs783Js88",
        "outputId": "71bf92bb-40d0-449c-f015-8044f87faf17"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:\n",
            "['i', 'am', 'a', 'student', 'hello', 'there', 'is', 'a', 'session', 'going', 'onn']\n",
            "\n",
            "POS Tagging:\n",
            "[('i', 'NN'), ('am', 'VBP'), ('a', 'DT'), ('student', 'NN'), ('hello', 'NN'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('session', 'NN'), ('going', 'VBG'), ('onn', 'NN')]\n",
            "\n",
            "Filtered Tokens after Stop Words Removal:\n",
            "['student', 'hello', 'session', 'going', 'onn']\n",
            "\n",
            "Stemmed Tokens:\n",
            "['student', 'hello', 'session', 'go', 'onn']\n",
            "\n",
            "Lemmatized Tokens:\n",
            "['i', 'be', 'a', 'student', 'hello', 'there', 'be', 'a', 'session', 'go', 'onn']\n",
            "\n",
            "TF-IDF Representation:\n",
            "  (0, 4)\t0.35355339059327373\n",
            "  (0, 1)\t0.35355339059327373\n",
            "  (0, 5)\t0.35355339059327373\n",
            "  (0, 3)\t0.35355339059327373\n",
            "  (0, 7)\t0.35355339059327373\n",
            "  (0, 2)\t0.35355339059327373\n",
            "  (0, 6)\t0.35355339059327373\n",
            "  (0, 0)\t0.35355339059327373\n"
          ]
        }
      ]
    }
  ]
}